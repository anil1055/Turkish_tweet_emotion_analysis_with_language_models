{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading data for Turkish text classification"
      ],
      "metadata": {
        "id": "cU4qf1kif8BS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv(\"tweets.csv\")\n",
        "df.columns=[\"labels\",\"text\"]\n",
        "df.labels=pd.Categorical(df.labels)\n",
        "df['labels'] = pd.factorize(df.labels)[0]"
      ],
      "metadata": {
        "id": "tNwPTVBBf6Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply pre-processing"
      ],
      "metadata": {
        "id": "gH6CecBOFg2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#just Tweet\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "for i in range(4000):\n",
        "    t = str(df.Tweets[i])\n",
        "    text_tokens = word_tokenize(t)\n",
        "    tokens_without_sw = [word for word in text_tokens if not word in stopwords]\n",
        "    total_words = list(set(tokens_without_sw))\n",
        "    filtered_sentence = (\" \").join(total_words)\n",
        "    df.loc[i, \"Tweets\"] = filtered_sentence[:-1]"
      ],
      "metadata": {
        "id": "UUpzgGNjgGTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split"
      ],
      "metadata": {
        "id": "A_z-JUM3Foc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split a dataset into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, eval_df = train_test_split(df, test_size=0.2)"
      ],
      "metadata": {
        "id": "5yEoi_XJgMSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Language Models"
      ],
      "metadata": {
        "id": "yZTLuNKSgStQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from simpletransformers.classification import ClassificationModel\n",
        "import torch,sklearn"
      ],
      "metadata": {
        "id": "r4o6DwhtFlvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelb = ClassificationModel('bert', 'dbmdz/bert-base-turkish-uncased', num_labels=5,\n",
        "                            args={'reprocess_input_data': True, 'overwrite_output_dir': True, 'num_train_epochs': 3})\n",
        "\n",
        "modelb.train_model(train_df, acc=sklearn.metrics.accuracy_score)\n",
        "\n",
        "modelbm = ClassificationModel('bert', 'bert-base-multilingual-uncased', num_labels=5,\n",
        "                            args={'reprocess_input_data': True, 'overwrite_output_dir': True, 'num_train_epochs': 3})\n",
        "\n",
        "modelbm.train_model(train_df, acc=sklearn.metrics.accuracy_score)\n",
        "\n",
        "modeld = ClassificationModel('distilbert', 'dbmdz/distilbert-base-turkish-cased', num_labels=5,\n",
        "                            args={'reprocess_input_data': True, 'overwrite_output_dir': True, 'num_train_epochs': 3})\n",
        "\n",
        "modeld.train_model(train_df, acc=sklearn.metrics.accuracy_score)"
      ],
      "metadata": {
        "id": "uci1XhqSgUt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing Language Models"
      ],
      "metadata": {
        "id": "ZebqxmuPgXn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = eval_df\n",
        "result, model_outputs, wrong_predictions = modelb.eval_model(test)\n",
        "predictions = model_outputs.argmax(axis=1)\n",
        "actuals = test.labels.values\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(actuals, predictions))"
      ],
      "metadata": {
        "id": "sq86v3CHgWoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = eval_df\n",
        "result, model_outputs, wrong_predictions = modelbm.eval_model(test)\n",
        "predictions = model_outputs.argmax(axis=1)\n",
        "actuals = test.labels.values\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(actuals, predictions))"
      ],
      "metadata": {
        "id": "3cl6M6fFGEh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = eval_df\n",
        "result, model_outputs, wrong_predictions = modeld.eval_model(test)\n",
        "predictions = model_outputs.argmax(axis=1)\n",
        "actuals = test.labels.values\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(actuals, predictions))"
      ],
      "metadata": {
        "id": "vggN6_bzGFRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = test.iloc[10]['text']\n",
        "print(sample_text)\n",
        "model.predict([sample_text])\n",
        "test.iloc[10]['labels']"
      ],
      "metadata": {
        "id": "9SgE94CDgeg4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}